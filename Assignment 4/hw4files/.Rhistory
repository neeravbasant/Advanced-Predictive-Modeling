reg_model.poisson <- rpart(mpg ~ ., data=train, method="poisson",control = rpart.control(xval=5,cp=0.0001))
plot(reg_model.poisson)
text(reg_model.poisson, use.n = TRUE)
title("Decision tree with 5 fold cross validation-poisson")
reg_prune.poisson <- prune(reg_model.poisson,cp=0.0087)
plot(reg_prune.poisson)
text(reg_prune.poisson, use.n = TRUE)
yhat.train.p=predict(reg_prune.poisson,newdata= train)
plot(yhat.train.p,train$mpg)
abline (0,1)
mse.train.p = mean((yhat.train.p - train$mpg)^2)
yhat.test.p=predict(reg_prune.poisson,newdata= test)
plot(yhat.test.p,test$mpg)
abline (0,1)
mse.test.p = mean((yhat.test.p - test$mpg)^2)
mse.train.p
mse.test.p
#install.packages('ROCR')
library(glmnet)
library(ROCR)
rm(list = ls())
#Read Table
df <- read.table(
"https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data",
sep=","
);
attach(df)
# Remove column V2 and scale all the independent variables
drops <- c("V2")
df <- df[,!(names(df) %in% drops)]
df.dat <- scale(df[,!(names(df) %in% c("V35"))])
df.dat<-as.data.frame(df.dat)
df.dat$v35 = ifelse(df.dat$V35 == 'g',1,0)
f.dat$dep = ifelse(df.dat$V35 == 'g',1,0)
df.dat$dep = ifelse(df.dat$V35 == 'g',1,0)
View(df.dat)
#install.packages('ROCR')
library(glmnet)
library(ROCR)
rm(list = ls())
#Read Table
df <- read.table(
"https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data",
sep=","
);
View(df)
attach(df)
View(df)
drops <- c("V2")
df <- df[,!(names(df) %in% drops)]
df.dat$v35 <- ifelse(df.dat$V35 == 'g',1,0)
df$v35 <- ifelse(df$V35 == 'g',1,0)
View(df)
df$V35 <- ifelse(df$V35 == 'g',1,0)
View(df)
#install.packages('ROCR')
library(glmnet)
library(ROCR)
rm(list = ls())
#Read Table
df <- read.table(
"https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data",
sep=","
);
attach(df)
# Remove column V2 and scale all the independent variables
drops <- c("V2")
df <- df[,!(names(df) %in% drops)]
df$V35 <- ifelse(df$V35 == 'g',1,0)
df.dat <- scale(df[,!(names(df) %in% c("V35"))])
df.dat<-as.data.frame(df.dat)
df.dat$V35 <- df[,c("V35")]
View(df.dat)
set.seed(123)
df.dat <- df.dat[sample(nrow(df.dat)), ]
bound <- floor(nrow(df.dat)*0.7)
df.dat.train <- df.dat[1:bound, ]
df.dat.test <- df.dat[(bound+1):nrow(df.dat), ]
df.dat.train.x<-df.dat.train[,!(names(df.dat.train) %in% c("V35"))]
df.dat.train.y<-df.dat.train$V35
df.dat.test.x<-df.dat.test[,!(names(df.dat.test) %in% c("V35"))]
df.dat.test.y<-df.dat.test$V35
df.dat.train.x<-as.matrix(df.dat.train.x)
df.dat.test.x<-as.matrix(df.dat.test.x)
?cv.glmnet
?glmnet
cv.out =cv.glmnet(df.dat.train.x,df.dat.train.y,alpha =0,nfolds=10,family="binomial")
par(mfrow=c(1,1))
plot(cv.out)
bestlam =cv.out$lambda.min
bestlam
ridge.prob.train=predict(cv.out,s=bestlam,newx=df.dat.train.x,type="response")
ridge.pred.train=rep(0 ,245)
ridge.pred.train[ridge.prob.train>.5]=1
train.error.rate <- mean((ridge.pred.train==0 & df.dat.train.y==1) |
(ridge.pred.train==1 & df.dat.train.y==0))
#Test
ridge.prob.test=predict(cv.out,s=bestlam,newx=df.dat.test.x,type="response")
ridge.pred.test=rep(0,106)
ridge.pred.test[ridge.prob.test>.5]=1
test.error.rate <- mean((ridge.pred.test==0 & df.dat.test.y==1) |
(ridge.pred.test==1 & df.dat.test.y==0))
train.error.rate
test.error.rate
pred <- prediction(ridge.pred.test,df.dat.test.y)
perf <- performance(pred,"tpr","fpr")
plot(perf, main="ROC curve", colorize=T)
auc.tmp <- performance(pred,"auc")
auc <- as.numeric(auc.tmp@y.values)
auc
lift<- performance(pred, "lift", "rpp")
plot(lift, main="Lift curve", colorize=T)
plot(perf, main="ROC curve", colorize=T)
plot(lift, main="Lift curve", colorize=T)
lift<- performance(pred, "lift", "rpp")
plot(lift, main="Lift curve", colorize=T)
library(rpart)
library(rpart.plot)
setwd("C:/Users/Neerav Basant/Desktop/Fall Semester/Advanced Predictive Modeling/Assignments/Assignment 4/hw4files/")
train <- read.table("data.train",sep=',',header=TRUE)
test <- read.table("data.test",sep=',',header=TRUE)
attach(train)
reg_model <- rpart(mpg ~ ., data=train, method="anova",control = rpart.control(xval=5,cp=0.0001))
#Plot Model
rpart.plot(reg_model)
text(reg_model, use.n = TRUE)
title("Decision tree with 5 fold cross validation")
plotcp(reg_model)
printcp(reg_model)
reg_prune <- prune(reg_model,cp=0.011)
reg_prune <- prune(reg_model,cp=0.01170368)
rpart.plot(reg_prune)
text(reg_prune, use.n = TRUE)
rpart.plot(reg_prune)
text(reg_prune, use.n = TRUE)
prp(reg_prune, main="Regression Tree Plot",
nn=TRUE,             # display the node numbers
fallen.leaves=TRUE,  # put the leaves on the bottom of the page
branch=.5,           # change angle of branch lines
faclen=0,            # do not abbreviate factor levels
trace=1,             # print the automatically calculated cex
shadow.col="gray",   # shadows under the leaves
branch.lty=3,        # draw branches using dotted lines
split.cex=1.2,       # make the split text larger than the node text
split.prefix="is ",  # put "is " before split text
split.suffix="?",    # put "?" after split text
split.box.col="lightgray",   # lightgray split boxes (default is white)
split.border.col="darkgray", # darkgray border on split boxes
split.round=.5,
under.font=15)
rpart.plot(reg_prune)
text(reg_prune, use.n = TRUE)
prp(reg_prune, main="Regression Tree Plot - Pruned",
nn=TRUE,             # display the node numbers
fallen.leaves=TRUE,  # put the leaves on the bottom of the page
branch=.5,           # change angle of branch lines
faclen=0,            # do not abbreviate factor levels
trace=1,             # print the automatically calculated cex
shadow.col="gray",   # shadows under the leaves
branch.lty=3,        # draw branches using dotted lines
split.cex=1.2,       # make the split text larger than the node text
split.prefix="is ",  # put "is " before split text
split.suffix="?",    # put "?" after split text
split.box.col="lightgray",   # lightgray split boxes (default is white)
split.border.col="darkgray", # darkgray border on split boxes
split.round=.5,
under.font=15)
yhat.train=predict(reg_prune,newdata= train)
plot(yhat.train,train$mpg)
abline (0,1)
mse.train = mean((yhat.train - train$mpg)^2)
mse.train
yhat.test=predict(reg_prune,newdata= test)
plot(yhat.test,test$mpg)
abline (0,1)
mse.test = mean((yhat.test - test$mpg)^2)
mse.test
pred.train=predict(reg_prune,newdata= train)
plot(pred.train,train$mpg)
abline (0,1)
title("Actual MPG vs Predicted MPG - Train")
mse.train = mean((pred.train - train$mpg)^2)
mse.train
pred.test=predict(reg_prune,newdata= test)
plot(pred.test,test$mpg)
abline (0,1)
title("Actual MPG vs Predicted MPG - Test")
mse.test = mean((pred.test - test$mpg)^2)
mse.test
reg_model.poisson <- rpart(mpg ~ ., data=train, method="poisson",control = rpart.control(xval=5,cp=0.0001))
plot(reg_model.poisson)
text(reg_model.poisson, use.n = TRUE)
title("Decision tree with 5 fold cross validation - Poisson")
reg_model.poisson <- rpart(mpg ~ ., data=train, method="poisson",control = rpart.control(xval=5,cp=0.0001))
rpart.plot(reg_model.poisson)
text(reg_model.poisson, use.n = TRUE)
title("Decision tree with 5 fold cross validation - Poisson")
plotcp(reg_model.poisson)
printcp(reg_model.poisson)
reg_prune.poisson <- prune(reg_model.poisson,cp=0.00872413)
plot(reg_prune.poisson)
text(reg_prune.poisson, use.n = TRUE)
rpart.plot(reg_prune.poisson)
text(reg_prune.poisson, use.n = TRUE)
pred.train.p=predict(reg_prune.poisson,newdata= train)
plot(pred.train.p,train$mpg)
abline (0,1)
title("Actual MPG vs Predicted MPG - Train (Poisson)")
mse.train.p = mean((pred.train.p - train$mpg)^2)
pred.test.p=predict(reg_prune.poisson,newdata= test)
plot(pred.test.p,test$mpg)
abline (0,1)
title("Actual MPG vs Predicted MPG - Test (Poisson)")
mse.test.p = mean((pred.test.p - test$mpg)^2)
mse.train.p
mse.test.p
library(rpart)
library(rpart.plot)
rm(list = ls())
setwd("C:/Users/Neerav Basant/Desktop/Fall Semester/Advanced Predictive Modeling/Assignments/Assignment 4/hw4files/")
train <- read.table("data.train",sep=',',header=TRUE)
test <- read.table("data.test",sep=',',header=TRUE)
attach(train)
# 3(a)
reg_model <- rpart(mpg ~ ., data=train, method="anova",control = rpart.control(xval=5,cp=0.0001))
rpart.plot(reg_model)
text(reg_model, use.n = TRUE)
title("Decision tree with 5 fold cross validation")
# 3(b)
plotcp(reg_model)
printcp(reg_model)
reg_prune <- prune(reg_model,cp=0.01170368)
rpart.plot(reg_prune)
text(reg_prune, use.n = TRUE)
# 3(c)
prp(reg_prune, main="Regression Tree Plot - Pruned",
nn=TRUE,             # display the node numbers
fallen.leaves=TRUE,  # put the leaves on the bottom of the page
branch=.5,           # change angle of branch lines
faclen=0,            # do not abbreviate factor levels
trace=1,             # print the automatically calculated cex
shadow.col="gray",   # shadows under the leaves
branch.lty=3,        # draw branches using dotted lines
split.cex=1.2,       # make the split text larger than the node text
split.prefix="is ",  # put "is " before split text
split.suffix="?",    # put "?" after split text
split.box.col="lightgray",   # lightgray split boxes (default is white)
split.border.col="darkgray", # darkgray border on split boxes
split.round=.5,
under.font=15)
# 3(d)
pred.train=predict(reg_prune,newdata= train)
plot(pred.train,train$mpg)
abline (0,1)
title("Actual MPG vs Predicted MPG - Train")
mse.train = mean((pred.train - train$mpg)^2)
mse.train
pred.test=predict(reg_prune,newdata= test)
plot(pred.test,test$mpg)
abline (0,1)
title("Actual MPG vs Predicted MPG - Test")
mse.test = mean((pred.test - test$mpg)^2)
mse.test
# 3(e)
reg_model.poisson <- rpart(mpg ~ ., data=train, method="poisson",control = rpart.control(xval=5,cp=0.0001))
rpart.plot(reg_model.poisson)
text(reg_model.poisson, use.n = TRUE)
title("Decision tree with 5 fold cross validation - Poisson")
plotcp(reg_model.poisson)
printcp(reg_model.poisson)
reg_prune.poisson <- prune(reg_model.poisson,cp=0.00872413)
rpart.plot(reg_prune.poisson)
text(reg_prune.poisson, use.n = TRUE)
pred.train.p=predict(reg_prune.poisson,newdata= train)
plot(pred.train.p,train$mpg)
abline (0,1)
title("Actual MPG vs Predicted MPG - Train (Poisson)")
mse.train.p = mean((pred.train.p - train$mpg)^2)
mse.train.p
pred.test.p=predict(reg_prune.poisson,newdata= test)
plot(pred.test.p,test$mpg)
abline (0,1)
title("Actual MPG vs Predicted MPG - Test (Poisson)")
mse.test.p = mean((pred.test.p - test$mpg)^2)
mse.test.p
library(rpart)
library(rpart.plot)
rm(list = ls())
setwd("C:/Users/Neerav Basant/Desktop/Fall Semester/Advanced Predictive Modeling/Assignments/Assignment 4/hw4files/")
train <- read.table("data.train",sep=',',header=TRUE)
test <- read.table("data.test",sep=',',header=TRUE)
attach(train)
# 3(a)
reg_model <- rpart(mpg ~ ., data=train, method="anova",control = rpart.control(xval=5,cp=0.0001))
rpart.plot(reg_model)
text(reg_model, use.n = TRUE)
title("Decision tree with 5 fold cross validation")
# 3(b)
plotcp(reg_model)
printcp(reg_model)
reg_prune <- prune(reg_model,cp=0.01170368)
rpart.plot(reg_prune)
text(reg_prune, use.n = TRUE)
# 3(c)
prp(reg_prune, main="Regression Tree Plot - Pruned",
nn=TRUE,             # display the node numbers
fallen.leaves=TRUE,  # put the leaves on the bottom of the page
branch=.5,           # change angle of branch lines
faclen=0,            # do not abbreviate factor levels
trace=1,             # print the automatically calculated cex
shadow.col="gray",   # shadows under the leaves
branch.lty=3,        # draw branches using dotted lines
split.cex=1.2,       # make the split text larger than the node text
split.prefix="is ",  # put "is " before split text
split.suffix="?",    # put "?" after split text
split.box.col="lightgray",   # lightgray split boxes (default is white)
split.border.col="darkgray", # darkgray border on split boxes
split.round=.5,
under.font=15)
# 3(d)
pred.train=predict(reg_prune,newdata= train)
plot(pred.train,train$mpg)
abline (0,1)
title("Actual MPG vs Predicted MPG - Train")
mse.train = mean((pred.train - train$mpg)^2)
mse.train
pred.test=predict(reg_prune,newdata= test)
plot(pred.test,test$mpg)
abline (0,1)
title("Actual MPG vs Predicted MPG - Test")
mse.test = mean((pred.test - test$mpg)^2)
mse.test
# 3(e)
reg_model.poisson <- rpart(mpg ~ ., data=train, method="poisson",control = rpart.control(xval=5,cp=0.0001))
rpart.plot(reg_model.poisson)
text(reg_model.poisson, use.n = TRUE)
title("Decision tree with 5 fold cross validation - Poisson")
plotcp(reg_model.poisson)
printcp(reg_model.poisson)
reg_prune.poisson <- prune(reg_model.poisson,cp=0.00872413)
rpart.plot(reg_prune.poisson)
text(reg_prune.poisson, use.n = TRUE)
pred.train.p=predict(reg_prune.poisson,newdata= train)
plot(pred.train.p,train$mpg)
abline (0,1)
title("Actual MPG vs Predicted MPG - Train (Poisson)")
mse.train.p = mean((pred.train.p - train$mpg)^2)
mse.train.p
pred.test.p=predict(reg_prune.poisson,newdata= test)
plot(pred.test.p,test$mpg)
abline (0,1)
title("Actual MPG vs Predicted MPG - Test (Poisson)")
mse.test.p = mean((pred.test.p - test$mpg)^2)
mse.test.p
#install.packages('ROCR')
library(glmnet)
library(ROCR)
rm(list = ls())
#Read Table
df <- read.table(
"https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data",
sep=","
);
attach(df)
# Remove column V2 and scale all the independent variables
drops <- c("V2")
df <- df[,!(names(df) %in% drops)]
df$V35 <- ifelse(df$V35 == 'g',1,0)
df.dat <- scale(df[,!(names(df) %in% c("V35"))])
df.dat<-as.data.frame(df.dat)
df.dat$V35 <- df[,c("V35")]
# Split the given dataset into training and test set
set.seed(123)
df.dat <- df.dat[sample(nrow(df.dat)), ]
bound <- floor(nrow(df.dat)*0.7)
df.dat.train <- df.dat[1:bound, ]
df.dat.test <- df.dat[(bound+1):nrow(df.dat), ]
df.dat.train.x<-df.dat.train[,!(names(df.dat.train) %in% c("V35"))]
df.dat.train.y<-df.dat.train$V35
df.dat.test.x<-df.dat.test[,!(names(df.dat.test) %in% c("V35"))]
df.dat.test.y<-df.dat.test$V35
df.dat.train.x<-as.matrix(df.dat.train.x)
df.dat.test.x<-as.matrix(df.dat.test.x)
# 2(a)
###############################################
##### Running a ridge logistic regression #####
###############################################
cv.out =cv.glmnet(df.dat.train.x,df.dat.train.y,alpha =0,nfolds=10,family="binomial")
par(mfrow=c(1,1))
plot(cv.out)
bestlam =cv.out$lambda.min
bestlam
set.seed(123)
library(glmnet)
library(ROCR)
rm(list = ls())
#Read Table
df <- read.table(
"https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data",
sep=","
);
attach(df)
# Remove column V2 and scale all the independent variables
drops <- c("V2")
df <- df[,!(names(df) %in% drops)]
df$V35 <- ifelse(df$V35 == 'g',1,0)
df.dat <- scale(df[,!(names(df) %in% c("V35"))])
df.dat<-as.data.frame(df.dat)
df.dat$V35 <- df[,c("V35")]
# Split the given dataset into training and test set
set.seed(123)
df.dat <- df.dat[sample(nrow(df.dat)), ]
bound <- floor(nrow(df.dat)*0.7)
df.dat.train <- df.dat[1:bound, ]
df.dat.test <- df.dat[(bound+1):nrow(df.dat), ]
df.dat.train.x<-df.dat.train[,!(names(df.dat.train) %in% c("V35"))]
df.dat.train.y<-df.dat.train$V35
df.dat.test.x<-df.dat.test[,!(names(df.dat.test) %in% c("V35"))]
df.dat.test.y<-df.dat.test$V35
df.dat.train.x<-as.matrix(df.dat.train.x)
df.dat.test.x<-as.matrix(df.dat.test.x)
# 2(a)
###############################################
##### Running a ridge logistic regression #####
###############################################
cv.out =cv.glmnet(df.dat.train.x,df.dat.train.y,alpha =0,nfolds=10,family="binomial")
par(mfrow=c(1,1))
plot(cv.out)
bestlam =cv.out$lambda.min
#Model probability and prediction
#Train
ridge.prob.train=predict(cv.out,s=bestlam,newx=df.dat.train.x,type="response")
ridge.pred.train=rep(0 ,245)
ridge.pred.train[ridge.prob.train>.5]=1
train.error.rate <- mean((ridge.pred.train==0 & df.dat.train.y==1) |
(ridge.pred.train==1 & df.dat.train.y==0))
#Test
ridge.prob.test=predict(cv.out,s=bestlam,newx=df.dat.test.x,type="response")
ridge.pred.test=rep(0,106)
ridge.pred.test[ridge.prob.test>.5]=1
test.error.rate <- mean((ridge.pred.test==0 & df.dat.test.y==1) |
(ridge.pred.test==1 & df.dat.test.y==0))
#install.packages('ROCR')
library(glmnet)
library(ROCR)
rm(list = ls())
#Read Table
df <- read.table(
"https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data",
sep=","
);
attach(df)
# Remove column V2 and scale all the independent variables
drops <- c("V2")
df <- df[,!(names(df) %in% drops)]
df$V35 <- ifelse(df$V35 == 'g',1,0)
df.dat <- scale(df[,!(names(df) %in% c("V35"))])
df.dat<-as.data.frame(df.dat)
df.dat$V35 <- df[,c("V35")]
# Split the given dataset into training and test set
set.seed(123)
df.dat <- df.dat[sample(nrow(df.dat)), ]
bound <- floor(nrow(df.dat)*0.7)
df.dat.train <- df.dat[1:bound, ]
df.dat.test <- df.dat[(bound+1):nrow(df.dat), ]
df.dat.train.x<-df.dat.train[,!(names(df.dat.train) %in% c("V35"))]
df.dat.train.y<-df.dat.train$V35
df.dat.test.x<-df.dat.test[,!(names(df.dat.test) %in% c("V35"))]
df.dat.test.y<-df.dat.test$V35
df.dat.train.x<-as.matrix(df.dat.train.x)
df.dat.test.x<-as.matrix(df.dat.test.x)
# 2(a)
###############################################
##### Running a ridge logistic regression #####
###############################################
cv.out =cv.glmnet(df.dat.train.x,df.dat.train.y,alpha =0,nfolds=10,family="binomial")
par(mfrow=c(1,1))
plot(cv.out)
bestlam =cv.out$lambda.min
#Model probability and prediction
#Train
ridge.prob.train=predict(cv.out,s=bestlam,newx=df.dat.train.x,type="response")
ridge.pred.train=rep(0 ,245)
ridge.pred.train[ridge.prob.train>.5]=1
train.error.rate <- mean((ridge.pred.train==0 & df.dat.train.y==1) |
(ridge.pred.train==1 & df.dat.train.y==0))
train.error.rate
#Test
ridge.prob.test=predict(cv.out,s=bestlam,newx=df.dat.test.x,type="response")
ridge.pred.test=rep(0,106)
ridge.pred.test[ridge.prob.test>.5]=1
test.error.rate <- mean((ridge.pred.test==0 & df.dat.test.y==1) |
(ridge.pred.test==1 & df.dat.test.y==0))
test.error.rate
# 2(b)
##################################################
##### Plotting ROC curve nad calculating AUC #####
##################################################
pred <- prediction(ridge.prob.test,df.dat.test.y)
perf <- performance(pred,"tpr","fpr")
plot(perf, main="ROC curve", colorize=T)
auc.tmp <- performance(pred,"auc")
auc <- as.numeric(auc.tmp@y.values)
auc
# 2(c)
###############################
##### Plotting lift curve #####
###############################
lift<- performance(pred, "lift", "rpp")
plot(lift, main="Lift curve", colorize=T)
plot(perf, main="ROC curve", colorize=T)
plot(lift, main="Lift curve", colorize=T)
